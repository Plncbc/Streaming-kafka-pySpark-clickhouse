services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_SERVER_ID: 1
    ports:
      - "2181:2181"
    networks:
      - kafka-net

  kafka-1:
    image: confluentinc/cp-kafka:latest
    ports:
      - "9092:9092"
      - "29092:29092"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-1:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_BROKER_ID: 1
      KAFKA_ENABLE_IDEMPOTENCE: "true"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
    depends_on:
      - zookeeper
    networks:
      - kafka-net

  kafka-2:
    image: confluentinc/cp-kafka:latest
    ports:
      - "9093:9093"
      - "29093:29093"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-2:19093,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9093,DOCKER://host.docker.internal:29093
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_BROKER_ID: 2
      KAFKA_ENABLE_IDEMPOTENCE: "true"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
    depends_on:
      - zookeeper
    networks:
      - kafka-net

  kafka-3:
    image: confluentinc/cp-kafka:latest
    ports:
      - "9094:9094"
      - "29094:29094"
    environment:
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka-3:19094,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9094,DOCKER://host.docker.internal:29094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_ZOOKEEPER_CONNECT: "zookeeper:2181"
      KAFKA_BROKER_ID: 3
      KAFKA_ENABLE_IDEMPOTENCE: "true"
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 2
    depends_on:
      - zookeeper
    networks:
      - kafka-net

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    depends_on:
      - kafka-1
      - kafka-2
      - kafka-3
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: custer_for_streaming
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka-1:19092,kafka-2:19093,kafka-3:19094
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
      KAFKA_CLUSTERS_0_JMXPORT: 9999
    networks:
      - kafka-net

  create-topics:
    image: confluentinc/cp-kafka:latest
    depends_on:
      - kafka-ui
    command: >
      sh -c '
        until kafka-topics --bootstrap-server kafka-1:19092 --list; do
          sleep 5;
        done;
        kafka-topics --create \
          --topic binance_agg_trade \
          --partitions 6 \
          --replication-factor 3 \
          --if-not-exists \
          --bootstrap-server kafka-1:19092,kafka-2:19093,kafka-3:19094;

          kafka-topics --create \
          --topic main_producer_status \
          --partitions 3 \
          --replication-factor 3 \
          --if-not-exists \
          --bootstrap-server kafka-1:19092,kafka-2:19093,kafka-3:19094;'
    networks:
      - kafka-net

  producer_main:
    image: python:latest
    depends_on:
      create-topics:
        condition: service_completed_successfully
    restart: on-failure
    working_dir: /app/main
    volumes:
      - ./producer:/app/main
      - ./cache_libs:/tmp/pip-cache
    command: >
      sh -c "pip install --cache-dir /tmp/pip-cache -r requirements.txt && python3 producer.py"
    networks:
      - kafka-net

  producer_backup:
    image: python:latest
    depends_on:
      create-topics:
        condition: service_completed_successfully
    restart: on-failure
    working_dir: /app/main
    volumes:
      - ./producer_backup:/app/main
      - ./cache_libs:/tmp/pip-cache
    command: >
      sh -c "pip install --cache-dir /tmp/pip-cache -r requirements.txt && python3 producer_backup.py"
    networks:
      - kafka-net

  spark-master:
    image: bitnami/spark:latest
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_PORT=7077
      - SPARK_KAFKA_BOOTSTRAP_SERVERS=kafka-1:19092
      - SPARK_HOME=/opt/bitnami/spark
    ports:
      - "8090:8080"
      - "7077:7077"
    volumes:

      - ./consumer_pyspark/:/app
    networks:
      - kafka-net

  spark-worker-1:
    image: bitnami/spark:latest
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2G
    networks:
      - kafka-net

  spark-worker-2:
    image: bitnami/spark:latest
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_CORES=2
      - SPARK_WORKER_MEMORY=2G
    networks:
      - kafka-net

  spark-submit-client:
    image: bitnami/spark:latest
    depends_on:
      create-topics:
        condition: service_completed_successfully
    command: >
      bash -c "
      /opt/bitnami/spark/bin/spark-submit \
      --master spark://spark-master:7077 \
      --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,com.clickhouse:clickhouse-jdbc:0.8.2 \
      /app/consumer.py"
    volumes:
      - ./spark_cache:/opt/bitnami/spark/.ivy2/cache
      - ./consumer_pyspark/:/app
    networks:
      - kafka-net

  clickhouse-server:
    image: clickhouse:latest
    container_name: clickhouse
    ports:
      - '8123:8123'
      - '9000:9000'
    volumes:
      - ./data:/var/lib/clickhouse
      - ./sql_scripts/:/docker-entrypoint-initdb.d
    environment:
      CLICKHOUSE_USER: "user"
      CLICKHOUSE_PASSWORD: "123"
    ulimits:
      nofile: 262144
    networks:
      - kafka-net
    
networks:
  kafka-net:
    driver: bridge